- name: Copy Docker elkserver project to target server
  copy: 
    src: ../dist/elkserver/
    dest: "{{ elkserver_dir }}"


- name: Set sysctl map count for Elasticsearch
  sysctl:
    name: vm.max_map_count
    value: 262144
    state: present
    reload: yes


- name: Add persistent Elastic (node1) data volume
  docker_volume:
    name: esdata_node1
    state: present


- name: Add persistent filesync data volume
  docker_volume:
    name: filesyncdata
    state: present


- name: Add persistent Kafka (node1) data volume
  docker_volume:
    name: kafkadata_node1
    state: present


- name: Create custom docker network for our analytics setup
  docker_network:
    name: analytics_network


- name: Run Redis container
  docker_container:
    name: redis_service
    image: redis
    state: started 


- name: Run zookeeper
  docker_container:
    name: zookeeper
    image: confluentinc/cp-zookeeper:latest
    state: started
    networks:
      - name: analytics_network
        aliases:
          - zookeeper                                   
    env:                                                                                 
      ZOOKEEPER_CLIENT_PORT: "2181"


- name: Run Kafka container
  docker_container:
    name: kafka
    image: confluentinc/cp-kafka:latest
    state: started
    networks:
      - name: analytics_network
        aliases:
          - kafka
        links:
          - zookeeper
    env:
      KAFKA_BROKER_ID: "1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://{{ kafka_ip }}:{{ kafka_port }}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
    ports:
      - "9092:9092"


- name: Run Elastic container
  docker_container:
    name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:6.6.0
    state: started
    networks:
      - name: analytics_network
        aliases:
          - elasticsearch
    env:
      cluster.name: "redelk-cluster"
      discovery.type: "single-node"
      bootstrap.memory_lock: "true"
      ES_JAVA_OPTS: "-Xms1024m -Xmx1024m"
    ulimits:
      - "memlock:-1:-1"
    volumes:
      - esdata_node1:/usr/share/elasticsearch/data
    ports:
      - "127.0.0.1:9200:9200"
  

- name: Run Kibana container
  docker_container:
    name: kibana
    image: docker.elastic.co/kibana/kibana:6.6.0
    state: started
    networks:
      - name: analytics_network
        aliases:
          - kibana
        links:
          - elasticsearch
    env:
      SERVER_NAME: "redelk-kibana"
      ELASTICSEARCH_HOSTS: "http://elasticsearch:9200"
      SERVER_HOST: "0.0.0.0"
    ports:
      - "5601:5601"


- name: Run logstash container
  docker_container:
    name: logstash
    image: docker.elastic.co/logstash/logstash:6.6.0
    state: started
    networks:
      - name: analytics_network
        aliases:
          - logstash
        links:
          - elasticsearch
          - kafka
    volumes:
      - "{{ elkserver_dir }}/logstash/conf.d:/usr/share/logstash/pipeline"


- name: Build filesync container
  docker_image:
    name: redelk/filesync
    path: "{{ elkserver_dir }}/filesync"
    force: yes
  

- name: Run filesync container
  docker_container:
    name: filesync
    image: redelk/filesync
    state: started
    recreate: yes
    volumes:
      - "{{ elkserver_dir }}/filesync/authorized_keys:/home/scponly/.ssh/authorized_keys"
      - "filesyncdata:/home/scponly/logs"
    ports:
      - "2222:22"


- name: Run NGINX container
  docker_container:
    name: nginx
    image: nginx
    state: started
    recreate: yes
    volumes:
      - "{{ elkserver_dir }}/nginx/conf/proxy.conf:/etc/nginx/conf.d/proxy.conf"
      - "filesyncdata:/var/www/html/cslogs"
    ports:
      - "80:80"

- name: Build enricher container
  docker_image:
    name: redelk/enricher
    path: "{{ elkserver_dir }}/enrich"
    force: yes
  

- name: Run enricher container
  docker_container:
    name: enricher
    image: redelk/enricher
    state: started
    recreate: yes
    networks:
      - name: analytics_network
        aliases:
          - enricher
        links:
          - elasticsearch
          - kafka
    volumes:
      - "{{ elkserver_dir }}/lookups:/enrich/lookups"


- name: Build intel container
  docker_image:
    name: redelk/intel
    path: "{{ elkserver_dir }}/intel"
    force: yes
  

- name: Run virustotal intel container every 15 min
  cron:
    name: "Run virustotal lookup container"
    minute: "*/15"
    job: "docker run -d --env VTKEY={{ intel_settings.vtkey }} -v {{ elkserver_dir }}/lookups:/etc/lookups --network='analytics_network' redelk/intel python producer.py virustotal"


- name: Run xforce intel container every 15 min
  cron:
    name: "Run xforce lookup container"
    minute: "*/15"
    job: "docker run -d --env XFORCEKEY={{ intel_settings.xforcekey }} --env XFORCEPASS={{ intel_settings.xforcepass }} -v {{ elkserver_dir }}/lookups:/etc/lookups --network='analytics_network' redelk/intel python producer.py xforce"


- name: Run greynoise intel container every 15 min
  cron:
    name: "Run greynoise lookup container"
    minute: "*/15"
    job: "docker run -d -v {{ elkserver_dir }}/lookups:/etc/lookups --network='analytics_network' redelk/intel python producer.py greynoise"


- name: Run hybridanalysis intel container every 15 min
  cron:
    name: "Run hybridanalysis lookup container"
    minute: "*/15"
    job: "docker run -d --env HAKEY={{ intel_settings.hakey }} -v {{ elkserver_dir }}/lookups:/etc/lookups --network='analytics_network' redelk/intel python producer.py hybridanalysis"
